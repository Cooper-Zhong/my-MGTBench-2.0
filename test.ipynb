{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = '/data1/models/Llama-2-7b-chat-hf'\n",
    "mask_model_name_or_path = '/data1/models/t5-base'\n",
    "from mgtbench import AutoDetector, AutoExperiment\n",
    "from mgtbench.loading.dataloader import load\n",
    "detectGPT = AutoDetector.from_detector_name('detectGPT', \n",
    "                                            model_name_or_path=model_name_or_path,\n",
    "                                            mask_model_name_or_path= mask_model_name_or_path)\n",
    "experiment = AutoExperiment.from_experiment_name('perturb',detector=[detectGPT])\n",
    "data = load('Essay', 'ChatGLM')\n",
    "data['train']['text']   =data['train']['text'] [:20]\n",
    "data['train']['label']=data['train']['label'][:20]\n",
    "data['test']['text']=data['test']['text'][:20]\n",
    "data['test']['label']=data['test']['label'][:20]\n",
    "experiment.load_data(data)\n",
    "experiment.launch(n_perturbations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-18 17:05:50,349] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae645872310e4e889961bf02688adc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423751b2b3154a0988989ce3cf914d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data: 100%|██████████| 997/997 [00:00<00:00, 10399.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector ll\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n",
      "Running prediction of detector rank\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DetectOutput(name='', train=Metric(acc=0.9, precision=0.9, recall=0.9, f1=0.9, auc=0.99), test=Metric(acc=0.9, precision=0.8333333333333334, recall=1.0, f1=0.9090909090909091, auc=0.9500000000000001)),\n",
       " DetectOutput(name='', train=Metric(acc=0.75, precision=0.7272727272727273, recall=0.8, f1=0.7619047619047619, auc=0.87), test=Metric(acc=0.6, precision=0.625, recall=0.5, f1=0.5555555555555556, auc=0.73))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = '/data1/models/Llama-2-7b-chat-hf'\n",
    "from mgtbench import AutoDetector, AutoExperiment\n",
    "from mgtbench.loading.dataloader import load\n",
    "metric1 = AutoDetector.from_detector_name('ll', \n",
    "                                            model_name_or_path=model_name_or_path)\n",
    "metric2 = AutoDetector.from_detector_name('rank', \n",
    "                                            model_name_or_path=model_name_or_path)\n",
    "experiment = AutoExperiment.from_experiment_name('threshold',detector=[metric1, metric2])\n",
    "data = load('Essay', 'ChatGLM')\n",
    "data['train']['text']   =data['train']['text'] [:20]\n",
    "data['train']['label']=data['train']['label'][:20]\n",
    "data['test']['text']=data['test']['text'][:20]\n",
    "data['test']['label']=data['test']['label'][:20]\n",
    "experiment.load_data(data)\n",
    "experiment.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data: 100%|██████████| 997/997 [00:00<00:00, 10431.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector demasq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:08<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 117.37925746122168\n",
      "Epoch [1/2], Val: f1 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:08<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 117.34796204075553\n",
      "Epoch [2/2], Val: f1 0.9166666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DetectOutput(name='', train=Metric(acc=0.99, precision=0.9803921568627451, recall=1.0, f1=0.9900990099009901, auc=1.0), test=Metric(acc=0.95, precision=1.0, recall=0.9, f1=0.9473684210526315, auc=0.96))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mgtbench import AutoDetector, AutoExperiment\n",
    "d = AutoDetector.from_detector_name('demasq', state_dict_path='model_weight')\n",
    "e = AutoExperiment.from_experiment_name('demasq',detector=[d])\n",
    "from mgtbench.loading.dataloader import load\n",
    "\n",
    "data = load('Essay', 'ChatGLM')\n",
    "data['train']['text']   =data['train']['text'] [:200]\n",
    "data['train']['label']=data['train']['label'][:200]\n",
    "data['test']['text']=data['test']['text'][:20]\n",
    "data['test']['label']=data['test']['label'][:20]\n",
    "len(data['train']['text'][0].split())\n",
    "e.load_data(data)\n",
    "e.launch(epoch=2,need_finetune=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /data1/models/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from mgtbench import AutoDetector, AutoExperiment\n",
    "detector = AutoDetector.from_detector_name('supervised', model_name_or_path='/data1/models/distilbert-base-uncased')\n",
    "experiment = AutoExperiment.from_experiment_name('supervised',detector=[detector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 206.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.50146484375]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.detect('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, fields, asdict\n",
    "@dataclass\n",
    "class A:\n",
    "    span_length:int = 2\n",
    "\n",
    "    def update(self, kargs):\n",
    "        for field in fields(self):\n",
    "            if field.name in kargs:\n",
    "                setattr(self, field.name, kargs[field.name])\n",
    "aa = A()\n",
    "aa.update({'span_length':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A(span_length=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-18 16:53:16,625] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a5f460eebb44bb81b20a53163bfca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data: 100%|██████████| 997/997 [00:00<00:00, 10256.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector detectGPT\n",
      "Predict training data\n",
      "Running perturb on the given texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturb finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n",
      "Running perturb on the given texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturb finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.50it/s]\n",
      "100%|██████████| 40/40 [00:04<00:00,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DetectOutput(name='', train=Metric(acc=0.9, precision=0.9, recall=0.9, f1=0.9, auc=0.9199999999999999), test=Metric(acc=0.85, precision=0.8181818181818182, recall=0.9, f1=0.8571428571428571, auc=0.92))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data: 100%|██████████| 997/997 [00:00<00:00, 10325.06it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = '/data1/models/distilbert-base-uncased'\n",
    "from mgtbench import AutoDetector, AutoExperiment\n",
    "from mgtbench.loading.dataloader import load\n",
    "\n",
    "detector = AutoDetector.from_detector_name('supervised', model_name_or_path=model_name_or_path)\n",
    "experiment = AutoExperiment.from_experiment_name('supervised',detector=[detector])\n",
    "data = load('Essay', 'ChatGLM')\n",
    "data['train']['text']   =data['train']['text'] [:20]\n",
    "data['train']['label']=data['train']['label'][:20]\n",
    "data['test']['text']=data['test']['text'][:20]\n",
    "data['test']['label']=data['test']['label'][:20]\n",
    "experiment.load_data(data)\n",
    "experiment.launch(n_perturbations=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data: 100%|██████████| 997/997 [00:00<00:00, 10423.87it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_data(data)\n",
    "experiment.loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerturbConfig(span_length=2, buffer_size=1, mask_top_p=1, pct_words_masked=0.3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.perturb_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate result for each data point\n",
      "Running prediction of detector LRR\n",
      "Predict training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.64it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  8.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run classification for results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/lyl/miniconda3/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DetectOutput(name='', train=Metric(acc=1.0, precision=1.0, recall=1.0, f1=1.0, auc=1.0), test=Metric(acc=0.5, precision=0.0, recall=0.0, f1=0.0, auc=1.0))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.171"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.Tensor([-2.1801, -2.1619])\n",
    "a = a.numpy()\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.66666667])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([2, 3])\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DEMASQ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DEMASQ, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import jn_zeros\n",
    "\n",
    "def compute_zeros(d, c_n):\n",
    "    m = d\n",
    "    n = c_n\n",
    "    drumhead_fundamental_f = jn_zeros(0,1)\n",
    "    drumhead_f = jn_zeros(m, n+1)\n",
    "    return drumhead_f[c_n]//drumhead_fundamental_f\n",
    "\n",
    "def source_frequency(emb):\n",
    "    min_emb = torch.min(emb)\n",
    "    max_emb = torch.max(emb)\n",
    "    if min_emb<0:\n",
    "        emb = emb + min_emb\n",
    "    else:\n",
    "        emb = emb - max_emb\n",
    "    unique_values = torch.unique(emb)\n",
    "    return compute_zeros(0, len(unique_values))\n",
    "\n",
    "def enery(emb, y):\n",
    "    c = torch.var(emb).cpu()\n",
    "    v_r = (1-y)*abs(c)\n",
    "    v_s = 0.8\n",
    "    E_f0 = source_frequency(emb)\n",
    "    E_f = (c+v_r)/(c-v_s)*E_f0\n",
    "    return E_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing data: 100%|██████████| 997/997 [00:00<00:00, 10402.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from mgtbench.loading.dataloader import load\n",
    "from  sentence_transformers import SentenceTransformer\n",
    "data = load('Essay', 'ChatGLM')\n",
    "model = SentenceTransformer('sentence-transformers/msmarco-distilbert-base-tas-b')\n",
    "train_embs = model.encode(data['train']['text'], convert_to_tensor=True)\n",
    "test_embs = model.encode(data['test']['text'], convert_to_tensor=True)\n",
    "train = list(zip(train_embs, data['train']['label']))\n",
    "test = list(zip(test_embs, data['test']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 12\n",
    "from torch.utils.data import DataLoader\n",
    "# Instantiate the model\n",
    "demasq = DEMASQ()\n",
    "demasq.cuda()\n",
    "optimizer = optim.Adam(demasq.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = demasq(torch.unsqueeze(train[0][0],dim=0).cuda())\n",
    "m = nn.Sigmoid()\n",
    "criterion(m(output), torch.Tensor([[train[0][1]]]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
